# NoesisForge

**NoesisForge** is a modern, AI-powered document management and intelligent search platform. It combines advanced document processing capabilities with artificial intelligence to provide semantic search, automated content analysis, and conversational interactions with your documents.

## ğŸŒŸ Overview

NoesisForge transforms how organizations handle document management by leveraging cutting-edge AI technologies. Upload documents, extract meaningful insights, and interact with your content through natural language queries. Whether you're managing legal documents, research papers, or business reports, NoesisForge makes your information instantly searchable and actionable.

## âœ¨ Key Features

### ğŸ“„ **Document Management**
- **Multi-format Support**: PDF, DOCX, TXT, and more
- **Intelligent Processing**: Automatic text extraction and metadata generation
- **Version Control**: Track document changes and revisions
- **Batch Processing**: Handle multiple documents simultaneously

### ğŸ” **Advanced Search Capabilities**
- **Semantic Search**: Find documents by meaning, not just keywords
- **Vector Similarity**: AI-powered document similarity matching
- **Full-text Search**: Traditional keyword-based search
- **Context-aware Results**: Intelligent ranking and relevance scoring

### ğŸ¤– **AI-Powered Features**
- **Multimodal Embeddings**: Text and image vector representations with BGE-M3 and SigLIP2
- **Hybrid Retrieval**: Dense, sparse, and multi-vector retrieval capabilities
- **Content Summarization**: Automatic document summaries via local LLM
- **Question Answering**: Ask questions about your documents with privacy-first local processing
- **Conversational Interface**: Chat with your document collection using Ollama models
- **Multilingual Support**: 100+ languages supported through BGE-M3

### ğŸ” **Security & Access Control**
- **Role-based Access Control (RBAC)**: Granular permission management
- **JWT Authentication**: Secure user authentication
- **Data Encryption**: End-to-end data protection
- **Audit Logging**: Track all system activities

### ğŸ“Š **Analytics & Monitoring**
- **Usage Analytics**: Understand how your documents are being used
- **Performance Metrics**: Real-time system monitoring
- **Search Analytics**: Insights into search patterns and effectiveness

## ğŸ—ºï¸ Development Roadmap

### Phase 1: Foundation
- âœ… **Core Infrastructure**
  - âœ… Project structure and Clean Architecture setup
  - âœ… Database connection and GORM integration
  - âœ… Environment configuration management
  - âœ… Middleware pipeline (CORS, Rate Limiting, Logging)

- âœ… **Authentication & Authorization System**
  - âœ… JWT token generation and validation
  - âœ… User registration and login endpoints
  - âœ… Role-based access control (RBAC)
  - âœ… Password hashing and security
  - âœ… Protected routes middleware

- âœ… **API Gateway Foundation**
  - âœ… Gin router setup and configuration
  - âœ… Rate limiting implementation
  - âœ… CORS policy configuration
  - âœ… Request/Response middleware
  - âœ… Error handling and logging

- âœ… **Health & Monitoring**
  - âœ… Health check endpoints
  - âœ… Database connectivity monitoring
  - âœ… Basic system status reporting

### Phase 2: Core Services
- â˜ **Document Management Service**
  - â˜ File upload endpoints (PDF, DOCX, TXT)
  - â˜ Document metadata extraction
  - â˜ File validation and sanitization
  - â˜ Document versioning system
  - â˜ Integration with MinIO object storage

- â˜ **Data Layer Expansion**
  - â˜ PostgreSQL optimizations and indexing
  - â˜ Redis cache layer integration
  - â˜ Qdrant vector database setup
  - â˜ MinIO object storage configuration

### Phase 3: AI/ML Pipeline
- â˜ **Embedding Service**
  - â˜ Text chunking algorithms
  - â˜ Integration with embedding models (BGE-M3, SigLIP)
  - â˜ Batch processing for large documents
  - â˜ Vector storage in Qdrant

- â˜ **AI/ML Pipeline**
  - â˜ Async processing with RabbitMQ
  - â˜ Embedding worker implementation
  - â˜ Content preprocessing pipeline
  - â˜ Multi-format document parsing

### Phase 4: Search & Retrieval
- â˜ **Search Service**
  - â˜ Full-text search implementation
  - â˜ Vector similarity search
  - â˜ Hybrid search (keyword + semantic)
  - â˜ Search result ranking and filtering
  - â˜ Advanced query processing

- â˜ **Search Optimization**
  - â˜ Query performance optimization
  - â˜ Result caching strategies
  - â˜ Search analytics and metrics

### Phase 5: Conversational AI
- â˜ **Chat Service**
  - â˜ Conversational AI interface
  - â˜ Context-aware response generation
  - â˜ Chat history management
  - â˜ Integration with LLM providers
  - â˜ Conversation threading

- â˜ **RAG Implementation**
  - â˜ Retrieval-Augmented Generation
  - â˜ Context injection for LLM queries
  - â˜ Response quality optimization
  - â˜ Citation and source tracking

### Phase 6: Advanced Features
- â˜ **Message Queue Integration**
  - â˜ RabbitMQ setup and configuration
  - â˜ Async job processing
  - â˜ Event-driven architecture
  - â˜ Job status tracking and monitoring

- â˜ **Advanced Monitoring**
  - â˜ Prometheus metrics integration
  - â˜ Grafana dashboards
  - â˜ Loki log aggregation
  - â˜ Performance monitoring
  - â˜ Alert management

- â˜ **Cache Layer Optimization**
  - â˜ Redis session management
  - â˜ Search result caching
  - â˜ API response caching
  - â˜ Cache invalidation strategies

### Phase 7: Production Readiness
- â˜ **Security Enhancements**
  - â˜ API security hardening
  - â˜ Input validation and sanitization
  - â˜ Rate limiting improvements
  - â˜ Security audit and testing

- â˜ **Performance & Scalability**
  - â˜ Database query optimization
  - â˜ Connection pooling
  - â˜ Horizontal scaling preparation
  - â˜ Load testing and optimization

- â˜ **DevOps & Deployment**
  - â˜ Docker containerization
  - â˜ CI/CD pipeline setup
  - â˜ Environment-specific configurations
  - â˜ Backup and recovery strategies


## ğŸ› ï¸ Tech Stack

### Backend
- **Language**: Go 1.24.2
- **Framework**: Gin (HTTP router)
- **Database**: PostgreSQL (metadata & relational data)
- **Vector Database**: Qdrant (document embeddings)
- **Object Storage**: MinIO (document files)
- **Cache**: Redis (session & query caching)
- **Message Queue**: RabbitMQ (async processing)
- **Authentication**: JWT tokens
- **Monitoring**: Prometheus + Grafana

### Frontend (Planned)
- **Framework**: Next.js 14 with React 18
- **Styling**: Tailwind CSS
- **State Management**: Zustand
- **HTTP Client**: Axios
- **UI Components**: Headless UI + Custom components
- **Type Safety**: TypeScript

### AI/ML Pipeline
- **Text Embedding**: [BGE-M3](https://huggingface.co/BAAI/bge-m3) - Multilingual embedding model (1024D, 8192 tokens, 100+ languages)
- **Image Embedding**: [SigLIP2](https://huggingface.co/google/siglip2-base-patch16-512) - Vision-language model for image understanding
- **Local LLM**: Ollama - Local language model runtime (supports Llama, Mistral, CodeLlama, etc.)
- **Vector Operations**: Qdrant native operations with hybrid retrieval support

### DevOps & Infrastructure
- **Containerization**: Docker & Docker Compose
- **Process Management**: Air (development hot reload)
- **Environment Management**: godotenv
- **Logging**: Logrus with structured logging
- **Configuration**: Environment variables + YAML

## ğŸš€ Getting Started

### Prerequisites
- **Go** 1.24.2 or higher
- **Node.js** 18+ (for frontend)
- **PostgreSQL** 13+
- **Redis** 6+
- **Ollama** (for local LLM)
- **Docker** & Docker Compose (recommended)

### Quick Start with Docker
```bash
# Clone the repository
git clone https://github.com/eyuppastirmaci/noesis-forge.git
cd noesis-forge

# Start all services
docker-compose up -d

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8080
```

### Manual Installation

#### Backend Setup
```bash
# Navigate to backend
cd backend

# Install dependencies
go mod download

# Set up environment
cp .env.example .env
# Edit .env with your configuration

# Run the application
go run cmd/api/main.go
```

#### Frontend Setup
```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Set up environment
cp .env.example .env.local
# Edit .env.local with your configuration

# Start development server
npm run dev
```

## ğŸ§ª Development

### Backend Development
```bash
cd backend

# Install Air for hot reload
go install github.com/cosmtrek/air@latest

# Run with hot reload
air

# Run tests
go test ./...

# Code formatting
go fmt ./...
```

### Frontend Development
```bash
cd frontend

# Start development server
npm run dev

# Run tests
npm run test

# Build for production
npm run build
```

## ğŸ“¦ Deployment

### Production Build
```bash
# Backend
cd backend
CGO_ENABLED=0 GOOS=linux go build -o bin/api cmd/api/main.go

# Frontend
cd frontend
npm run build
```

### Docker Deployment
```bash
# Build and run all services
docker-compose -f docker-compose.prod.yml up -d

# Scale specific services
docker-compose -f docker-compose.prod.yml up -d --scale api=3
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors & Contributors

- **Eyup Pastirmaci** - [@eyuppastirmaci](https://github.com/eyuppastirmaci)

## ğŸ™ Acknowledgments

- **[Beijing Academy of Artificial Intelligence (BAAI)](https://huggingface.co/BAAI/bge-m3)** for BGE-M3 multilingual embedding model
- **[Google Research](https://huggingface.co/google/siglip2-base-patch16-512)** for SigLIP2 vision-language model
- **[Ollama](https://ollama.com/)** for making local LLM deployment accessible and efficient
- **[Qdrant](https://qdrant.tech/)** team for the excellent vector database with hybrid retrieval support
- **[Hugging Face](https://huggingface.co/)** for providing a platform for AI model sharing
- **The Go community** for excellent tooling and libraries
- **React and Next.js teams** for frontend frameworks
- **All open-source contributors** who make projects like this possible


